{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Image and Steering angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(sample,pred_angle):\n",
    "    r\"\"\" Helper function for (batch) sample visualization\n",
    "    Args:\n",
    "        sample: Dictionary\n",
    "    \"\"\"\n",
    "    image_dims = len(sample['image'].shape)\n",
    "    assert image_dims <= 5, \"Unsupported image shape: {}\".format(sample['image'].shape)\n",
    "    if image_dims == 4:\n",
    "        error = abs(pred_angle - sample['angle'])\n",
    "        n = sample['image'].shape[0]\n",
    "        sample['image'] = torch.Tensor(resize(sample['image'], (n,3,480,640),anti_aliasing=True))\n",
    "        images = sample['image'].permute(0,2,3,1)\n",
    "        fig = plt.figure(figsize=(155, 135))\n",
    "        for i in range(n):\n",
    "            ax = fig.add_subplot(10,5,i+1)\n",
    "            ax.imshow(images[i])\n",
    "            ax.axis('off')\n",
    "            ax.set_title(\"t={}\".format(sample['timestamp'][i]))\n",
    "            ax.text(10, 30, sample['frame_id'][i], color='red')\n",
    "            ax.text(10, 390, \"error {:.3}\".format(error[i].item()), color='red')\n",
    "            ax.text(10, 430, \"man-angle {:.3}\".format(sample['angle'][i].item()), color='red')\n",
    "            ax.text(10, 470, \"pred-angle {:.3}\".format(pred_angle[i].item()), color='red')\n",
    "    else:\n",
    "        #error = abs(pred_angle - sample['angle'])\n",
    "        sample['image'] = sample['image'].permute(0,2,1,3,4)\n",
    "        batch_size,seq_len,channel = sample['image'].shape[0],sample['image'].shape[1],sample['image'].shape[2]\n",
    "        sample['image'] = torch.Tensor(resize(sample['image'], (batch_size,seq_len,3,480,640),anti_aliasing=True))\n",
    "        n0 = sample['image'].shape[0]\n",
    "        n1 = sample['image'].shape[1] if image_dims == 5 else 1\n",
    "        images_flattened = torch.flatten(sample['image'], end_dim=-4)\n",
    "        fig, ax = plt.subplots(n0, n1, figsize=(25, 15))\n",
    "        for i1 in range(n1):\n",
    "            for i0 in range(n0):\n",
    "                image = images_flattened[i0 * n1 + i1]\n",
    "                axis = ax[i0, i1]\n",
    "                axis.imshow(image.permute(1,2,0))\n",
    "                axis.axis('off')\n",
    "                axis.set_title(\"t={}\".format(sample['timestamp'][i0][i1]))\n",
    "                axis.text(10, 30, sample['frame_id'][i0][i1], color='red')\n",
    "                #axis.text(10, 390, \"error {:.3}\".format(error[i0][i1].item()), color='red')\n",
    "                axis.text(10, 430, \"man-angle {:.3}\".format(sample['angle'][i0][i1].item()), color='red')\n",
    "                axis.text(10, 470, \"pred-angle {:.3}\".format(pred_angle[i0][i1].item()), color='red')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing CNN filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_cnn(cnn, max_row=10, max_col=10, select_channel=None, tb_writer=None):\n",
    "    assert isinstance(cnn, nn.Conv3d) or isinstance(cnn, nn.Conv2d)\n",
    "    \n",
    "    filters = cnn.weight.cpu().detach().numpy() # output_ch x input_ch x D x H x W\n",
    "    output_ch = np.minimum(cnn.weight.shape[0], max_col)\n",
    "    input_ch = np.minimum(cnn.weight.shape[1], max_row)\n",
    "    print(filters.shape)\n",
    "    \n",
    "    if isinstance(cnn, nn.Conv3d):\n",
    "        if select_channel:\n",
    "            assert isinstance(select_channel, int)\n",
    "            filters = filters[:, :, select_channel, :, :]\n",
    "        else:\n",
    "            filters = np.mean(filters[:, :, :, :, :], axis=2)\n",
    "    \n",
    "    plt_idx = 0\n",
    "    fig = plt.figure(figsize=(output_ch, input_ch))\n",
    "    plt.xlabel(\"Output Channel\")\n",
    "    plt.ylabel(\"Input Channel\")\n",
    "    frame1 = plt.gca()\n",
    "    frame1.axes.xaxis.set_ticklabels([])\n",
    "    frame1.axes.yaxis.set_ticklabels([])\n",
    "    for o in range(output_ch):\n",
    "        for i in range(input_ch):\n",
    "            image = filters[o, i, :, :]\n",
    "            plt_idx += 1\n",
    "            ax = fig.add_subplot(input_ch, output_ch, plt_idx)\n",
    "            ax.imshow(image)\n",
    "            ax.axis('off')\n",
    "#     plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCAM (class activation mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "class CamExtractor():\n",
    "    \"\"\"\n",
    "        Extracts cam features from the model\n",
    "    \"\"\"\n",
    "    def __init__(self, model, register_hooks=True):\n",
    "        self.model = model\n",
    "        self.grad = None\n",
    "        self.conv_output = None\n",
    "        \n",
    "        if register_hooks:\n",
    "            self.register_hooks()\n",
    "        \n",
    "    def gradient_hook(self, model, grad_input, grad_output):\n",
    "        self.grad = grad_output[0].cpu().detach().numpy()\n",
    "        \n",
    "    def conv_output_hook(self, model, input, output):\n",
    "        self.conv_output = output.cpu().detach().numpy()\n",
    "        \n",
    "    def register_hooks(self):\n",
    "        raise NotImplementedError(\"You should implement this method for your own model!\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"You should implement this method for your own model!\")\n",
    "        \n",
    "    def to_image(self, height=None, width=None):\n",
    "        assert self.grad is not None and self.conv_output is not None, \"You should perform both forward pass and backward propagation first!\"\n",
    "        # both grad and conv_output should have the same dimension of: (*, channel, H, W)\n",
    "        # we produce image(s) of shape: (*, H, W)\n",
    "        channel_weight = np.mean(self.grad, axis=(-2, -1)) # *, channel\n",
    "        conv_permuted = np.moveaxis(self.conv_output, [-2, -1], [0, 1]) # H, W, *, channel\n",
    "        cam_image_permuted = channel_weight * conv_permuted # H, W, *, channel\n",
    "        cam_image_permuted = np.mean(cam_image_permuted, axis=-1) # H, W, *\n",
    "        cam_image = np.moveaxis(cam_image_permuted, [0, 1], [-2, -1]) # *, H, W\n",
    "        \n",
    "        if height is not None and width is not None:\n",
    "            image_shape = list(cam_image.shape)\n",
    "            image_shape[-2] = height\n",
    "            image_shape[-1] = width\n",
    "            cam_image = resize(cam_image, image_shape)\n",
    "        return cam_image\n",
    "        \n",
    "    \n",
    "class CamExtractorTLModel(CamExtractor):\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self.model.ResNet.layer4.register_forward_hook(self.conv_output_hook)\n",
    "        self.model.ResNet.layer4.register_backward_hook(self.gradient_hook)\n",
    "\n",
    "class CamExtractorTLModel_regnetx(CamExtractor):\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self.model.pretrained.trunk_output.block4.register_forward_hook(self.conv_output_hook)\n",
    "        self.model.pretrained.trunk_output.block4.register_backward_hook(self.gradient_hook)\n",
    "\n",
    "class CamExtractorTLModel_VGG(CamExtractor):\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self.model.pretrained.features[19:30].register_forward_hook(self.conv_output_hook)\n",
    "        self.model.pretrained.features[19:30].register_backward_hook(self.gradient_hook)\n",
    "\n",
    "class CamExtractorTLModel_EffNetB7(CamExtractor):\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self.model.pretrained.features[-1].register_forward_hook(self.conv_output_hook)\n",
    "        self.model.pretrained.features[-1].register_backward_hook(self.gradient_hook)\n",
    "\n",
    "\n",
    "class CamExtractorTLModel_wideresnet(CamExtractor):    \n",
    "    def register_hooks(self):\n",
    "        self.model.pretrained.layer4.register_forward_hook(self.conv_output_hook)\n",
    "        self.model.pretrained.layer4.register_backward_hook(self.gradient_hook)\n",
    "\n",
    "class CamExtractor3DCNN(CamExtractor):\n",
    "    \n",
    "    def gradient_hook(self, model, grad_input, grad_output):\n",
    "        grad = grad_output[0].cpu().detach().numpy()\n",
    "        self.grad = np.moveaxis(grad, 1, 2) # restore old dimension (batch x seq_len x channel x H x W)\n",
    "        \n",
    "    def conv_output_hook(self, model, input, output):\n",
    "        conv_output = output.cpu().detach().numpy()\n",
    "        self.conv_output = np.moveaxis(conv_output, 1, 2) # restore old dimension (batch x seq_len x channel x H x W)\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        self.model.Convolution6.register_forward_hook(self.conv_output_hook)\n",
    "        self.model.Convolution6.register_backward_hook(self.gradient_hook)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
